{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Authorship Identification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2.5: Basic Feature Engineering - Text b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tran = pd.read_json('../data/data2/data_tran.json', orient='records', lines=True)\n",
    "data_test = pd.read_json('../data/data2/data_test.json', orient='records', lines=True)\n",
    "\n",
    "n_tran = data_tran.shape[0]\n",
    "n_test = data_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_encoder = TfidfVectorizer(ngram_range=(1, 2))\n",
    "tfidf_encoder.fit(data_tran['text']) \n",
    "\n",
    "def get_top_tfidf_words(text, top_n):\n",
    "    tfidf_array = tfidf_encoder.transform([text]).toarray()[0]\n",
    "    top_indices = np.argsort(tfidf_array)[-top_n:][::-1] \n",
    "    return top_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 82/8460 [00:01<02:34, 54.26it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8460/8460 [02:17<00:00, 61.34it/s]\n"
     ]
    }
   ],
   "source": [
    "def get_word_author_dict(data, top_n):\n",
    "\n",
    "    num_authors = 21246\n",
    "    word_author_dict = {author_id: {} for author_id in range(num_authors)}\n",
    "\n",
    "    for _, row in tqdm(data.iterrows(), total=len(data)):\n",
    "        text = row['text'] \n",
    "        authors = row['authors'] \n",
    "\n",
    "        top_words = get_top_tfidf_words(text, top_n) \n",
    "\n",
    "        for author in authors:\n",
    "            if author >= 0: \n",
    "                for word_id in top_words:\n",
    "                    if word_id in word_author_dict[author]:\n",
    "                        word_author_dict[author][word_id] += 1\n",
    "                    else:\n",
    "                        word_author_dict[author][word_id] = 1\n",
    "\n",
    "    return word_author_dict\n",
    "\n",
    "word_author_dict = get_word_author_dict(data_tran, top_n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_vetcor(coauthor_list, word_author_dict):\n",
    "\n",
    "    result_array = np.zeros(100)\n",
    "\n",
    "    for coauthor in coauthor_list:\n",
    "        if coauthor not in word_author_dict:\n",
    "            continue \n",
    "\n",
    "        common_words = word_author_dict[coauthor].keys()\n",
    "        \n",
    "        for main_author in range(100):\n",
    "            if main_author not in word_author_dict:\n",
    "                continue \n",
    "            \n",
    "            for word in common_words:\n",
    "                if word in word_author_dict[main_author]:\n",
    "                    result_array[main_author] += word_author_dict[main_author][word]\n",
    "\n",
    "    return result_array.reshape(1, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_matrix(data, word_author_dict):\n",
    "    vectors_list = Parallel(n_jobs=-1)(delayed(get_text_vetcor)(row['coauthors'], word_author_dict) for _, row in tqdm(data.iterrows(), total=len(data)))\n",
    "    return np.concatenate(vectors_list, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8460/8460 [1:28:47<00:00,  1.59it/s]\n",
      "100%|██████████| 800/800 [08:03<00:00,  1.66it/s]\n"
     ]
    }
   ],
   "source": [
    "x_tran_text = get_text_matrix(data_tran, word_author_dict)\n",
    "x_test_text = get_text_matrix(data_test, word_author_dict)\n",
    "\n",
    "np.save('../data/data2/x_tran_text_b.npy', x_tran_text)\n",
    "np.save('../data/data2/x_test_text_b.npy', x_test_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
