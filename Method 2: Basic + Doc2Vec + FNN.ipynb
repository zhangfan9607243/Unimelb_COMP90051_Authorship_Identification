{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load original data in pandas\n",
    "data_tran = pd.read_json('data2/data_tran.json', orient='records', lines=True)\n",
    "data_test = pd.read_json('data2/data_test.json', orient='records', lines=True)\n",
    "\n",
    "n_tran = data_tran.shape[0]\n",
    "n_test = data_test.shape[0]\n",
    "\n",
    "# Load feature data in numpy\n",
    "x_tran_coauthors = np.load(\"data2/x_tran_coauthors.npy\")\n",
    "x_tran_venue_a   = np.load(\"data2/x_tran_venue_a.npy\")\n",
    "x_tran_venue_b   = np.load(\"data2/x_tran_venue_b.npy\")\n",
    "x_tran_text_a    = np.load(\"data2/x_tran_text_a.npy\")\n",
    "x_tran_text_b    = np.load(\"data2/x_tran_text_b.npy\")\n",
    "\n",
    "x_test_coauthors = np.load(\"data2/x_test_coauthors.npy\")\n",
    "x_test_venue_a   = np.load(\"data2/x_test_venue_a.npy\")\n",
    "x_test_venue_b   = np.load(\"data2/x_test_venue_b.npy\")\n",
    "x_test_text_a    = np.load(\"data2/x_test_text_a.npy\")\n",
    "x_test_text_b    = np.load(\"data2/x_test_text_b.npy\")\n",
    "\n",
    "x_tran_title_doc2vec = np.load('data2/x_tran_title_doc2vec.npy')\n",
    "x_test_title_doc2vec = np.load('data2/x_test_title_doc2vec.npy')\n",
    "\n",
    "x_tran_abstract_doc2vec = np.load('data2/x_tran_abstract_doc2vec.npy')\n",
    "x_test_abstract_doc2vec = np.load('data2/x_test_abstract_doc2vec.npy')\n",
    "\n",
    "y_tran_basic = np.load(\"data2/y_tran.npy\")\n",
    "x_tran_basic = np.concatenate((x_tran_coauthors, x_tran_venue_a, x_tran_venue_b, x_tran_text_a, x_tran_text_b), axis=1)\n",
    "x_test_basic = np.concatenate((x_test_coauthors, x_test_venue_a, x_test_venue_b, x_test_text_a, x_test_text_b), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Train-validation split\n",
    "idxs = np.random.permutation(n_tran)\n",
    "inxs_prop = int(0.85 * n_tran)\n",
    "idxs_tran_indices = idxs[:inxs_prop]\n",
    "idxs_vald_indices = idxs[inxs_prop:]\n",
    "\n",
    "x_tran_a = torch.tensor(x_tran_basic[idxs_tran_indices], dtype=torch.float32).to(device)\n",
    "x_vald_a = torch.tensor(x_tran_basic[idxs_vald_indices], dtype=torch.float32).to(device)\n",
    "x_test_a = torch.tensor(x_test_basic, dtype=torch.float32).to(device)\n",
    "\n",
    "x_tran_b = torch.tensor(x_tran_title_doc2vec[idxs_tran_indices], dtype=torch.float32).to(device)\n",
    "x_vald_b = torch.tensor(x_tran_title_doc2vec[idxs_vald_indices], dtype=torch.float32).to(device)\n",
    "x_test_b = torch.tensor(x_test_title_doc2vec, dtype=torch.float32).to(device)\n",
    "\n",
    "x_tran_c = torch.tensor(x_tran_abstract_doc2vec[idxs_tran_indices], dtype=torch.float32).to(device)\n",
    "x_vald_c = torch.tensor(x_tran_abstract_doc2vec[idxs_vald_indices], dtype=torch.float32).to(device)\n",
    "x_test_c = torch.tensor(x_test_abstract_doc2vec, dtype=torch.float32).to(device)\n",
    "\n",
    "y_tran   = torch.tensor(y_tran_basic[idxs_tran_indices], dtype=torch.float32).to(device)\n",
    "y_vald   = torch.tensor(y_tran_basic[idxs_vald_indices], dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class ModelDataset(Dataset):\n",
    "    def __init__(self, x1, x2, x3, y):\n",
    "        self.x1 = x1\n",
    "        self.x2 = x2\n",
    "        self.x3 = x3\n",
    "        self.y  = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x1)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x1 = self.x1[idx].clone().detach().float()\n",
    "        x2 = self.x2[idx].clone().detach().float()\n",
    "        x3 = self.x3[idx].clone().detach().float()\n",
    "        y  = self.y[idx].clone().detach().float()\n",
    "        return x1, x2, x3, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_tran = ModelDataset(x_tran_a, x_tran_b, x_tran_c, y_tran)\n",
    "datalod_tran = DataLoader(dataset_tran, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FNN(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim1, input_dim2, input_dim3, output_dim):\n",
    "        super(FNN, self).__init__()\n",
    "\n",
    "        self.model1 = nn.Sequential(\n",
    "            nn.Linear(input_dim1, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 50),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.model2 = nn.Sequential(\n",
    "            nn.Linear(input_dim2, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 50),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.model3 = nn.Sequential(\n",
    "            nn.Linear(input_dim3, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 100),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(200, output_dim)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x1, x2, x3):\n",
    "        x1 = self.model1(x1)\n",
    "        x2 = self.model2(x2)\n",
    "        x3 = self.model3(x3)\n",
    "\n",
    "        x = torch.cat((x1, x2, x3), dim=1)\n",
    "\n",
    "        x = self.fc(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim1 = x_tran_a.shape[1]\n",
    "input_dim2 = x_tran_b.shape[1]\n",
    "input_dim3 = x_tran_c.shape[1] \n",
    "output_dim = y_tran.shape[1] \n",
    "\n",
    "model = FNN(input_dim1, input_dim2, input_dim3, output_dim).to(device)\n",
    "criterion = nn.BCELoss() \n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00001, weight_decay=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "def calculate_metrics(pred_label, true_label):\n",
    "    pred_label = pred_label.int()\n",
    "    true_label = true_label.int()\n",
    "    pc = precision_score(true_label.cpu(), pred_label.cpu(), average='macro', zero_division=0)\n",
    "    rc = recall_score(true_label.cpu(), pred_label.cpu(), average='macro', zero_division=0)\n",
    "    f1 = f1_score(true_label.cpu(), pred_label.cpu(), average='macro', zero_division=0)\n",
    "    return pc, rc, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, delta=0.001):\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.best_loss = None\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, train_loss):\n",
    "        if self.best_loss is None or train_loss < self.best_loss - self.delta:\n",
    "            self.best_loss = train_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "early_stopping = EarlyStopping(patience=10, delta=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/50000, Loss: 0.0199\n",
      "Train - Precision: 0.8983, Recall: 0.5439, F1 Score: 0.6534\n",
      "Val   - Precision: 0.8075, Recall: 0.4590, F1 Score: 0.5623\n",
      "\n",
      "Epoch 200/50000, Loss: 0.0098\n",
      "Train - Precision: 0.9503, Recall: 0.8083, F1 Score: 0.8674\n",
      "Val   - Precision: 0.8652, Recall: 0.6182, F1 Score: 0.7044\n",
      "\n",
      "Epoch 300/50000, Loss: 0.0052\n",
      "Train - Precision: 0.9805, Recall: 0.9373, F1 Score: 0.9576\n",
      "Val   - Precision: 0.8671, Recall: 0.6771, F1 Score: 0.7478\n",
      "\n",
      "Epoch 400/50000, Loss: 0.0028\n",
      "Train - Precision: 0.9963, Recall: 0.9885, F1 Score: 0.9923\n",
      "Val   - Precision: 0.8686, Recall: 0.6952, F1 Score: 0.7606\n",
      "\n",
      "Epoch 500/50000, Loss: 0.0016\n",
      "Train - Precision: 0.9994, Recall: 0.9991, F1 Score: 0.9993\n",
      "Val   - Precision: 0.8757, Recall: 0.7002, F1 Score: 0.7674\n",
      "\n",
      "Epoch 600/50000, Loss: 0.0010\n",
      "Train - Precision: 1.0000, Recall: 0.9999, F1 Score: 0.9999\n",
      "Val   - Precision: 0.8694, Recall: 0.7068, F1 Score: 0.7695\n",
      "\n",
      "Epoch 700/50000, Loss: 0.0008\n",
      "Train - Precision: 1.0000, Recall: 0.9999, F1 Score: 0.9999\n",
      "Val   - Precision: 0.8804, Recall: 0.7112, F1 Score: 0.7762\n",
      "\n",
      "Epoch 800/50000, Loss: 0.0006\n",
      "Train - Precision: 1.0000, Recall: 1.0000, F1 Score: 1.0000\n",
      "Val   - Precision: 0.8744, Recall: 0.7172, F1 Score: 0.7776\n",
      "\n",
      "Epoch 900/50000, Loss: 0.0005\n",
      "Train - Precision: 1.0000, Recall: 1.0000, F1 Score: 1.0000\n",
      "Val   - Precision: 0.8708, Recall: 0.7273, F1 Score: 0.7829\n",
      "\n",
      "Epoch 1000/50000, Loss: 0.0005\n",
      "Train - Precision: 1.0000, Recall: 1.0000, F1 Score: 1.0000\n",
      "Val   - Precision: 0.8733, Recall: 0.7265, F1 Score: 0.7838\n",
      "\n",
      "Epoch 1100/50000, Loss: 0.0004\n",
      "Train - Precision: 1.0000, Recall: 1.0000, F1 Score: 1.0000\n",
      "Val   - Precision: 0.8771, Recall: 0.7297, F1 Score: 0.7874\n",
      "\n",
      "Epoch 1200/50000, Loss: 0.0004\n",
      "Train - Precision: 1.0000, Recall: 1.0000, F1 Score: 1.0000\n",
      "Val   - Precision: 0.8759, Recall: 0.7212, F1 Score: 0.7818\n",
      "\n",
      "Epoch 1400/50000, Loss: 0.0004\n",
      "Train - Precision: 1.0000, Recall: 1.0000, F1 Score: 1.0000\n",
      "Val   - Precision: 0.8798, Recall: 0.7287, F1 Score: 0.7876\n",
      "\n",
      "Epoch 1500/50000, Loss: 0.0004\n",
      "Train - Precision: 0.9996, Recall: 0.9999, F1 Score: 0.9997\n",
      "Val   - Precision: 0.8717, Recall: 0.7313, F1 Score: 0.7853\n",
      "\n",
      "Epoch 1600/50000, Loss: 0.0003\n",
      "Train - Precision: 1.0000, Recall: 1.0000, F1 Score: 1.0000\n",
      "Val   - Precision: 0.8795, Recall: 0.7285, F1 Score: 0.7882\n",
      "\n",
      "Epoch 1700/50000, Loss: 0.0003\n",
      "Train - Precision: 1.0000, Recall: 1.0000, F1 Score: 1.0000\n",
      "Val   - Precision: 0.8772, Recall: 0.7304, F1 Score: 0.7868\n",
      "\n",
      "Epoch 1800/50000, Loss: 0.0003\n",
      "Train - Precision: 1.0000, Recall: 1.0000, F1 Score: 1.0000\n",
      "Val   - Precision: 0.8714, Recall: 0.7271, F1 Score: 0.7833\n",
      "\n",
      "Epoch 1900/50000, Loss: 0.0003\n",
      "Train - Precision: 1.0000, Recall: 1.0000, F1 Score: 1.0000\n",
      "Val   - Precision: 0.8783, Recall: 0.7197, F1 Score: 0.7813\n",
      "\n",
      "Early Stop!\n"
     ]
    }
   ],
   "source": [
    "# 开始训练\n",
    "epochs = 50000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()  # 设置为训练模式\n",
    "\n",
    "    total_loss = 0  # 累计每个 epoch 的损失\n",
    "\n",
    "    # 遍历训练数据集\n",
    "    for batch in datalod_tran:\n",
    "        x1, x2, x3, y = batch\n",
    "        x1, x2, x3, y = x1.to(device), x2.to(device), x3.to(device), y.to(device)\n",
    "\n",
    "        # 前向传播\n",
    "        outputs = model(x1, x2, x3)\n",
    "        loss = criterion(outputs, y.float())\n",
    "\n",
    "        # 反向传播和优化\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(datalod_tran)  # 计算平均损失\n",
    "\n",
    "    # 每 1000 个 epoch 打印训练和验证结果\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        model.eval()  # 设置为评估模式\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # 计算训练集指标\n",
    "            y_tran_pred_prob = model(x_tran_a, x_tran_b, x_tran_c)\n",
    "            y_tran_pred_labl = (y_tran_pred_prob > 0.5).int()\n",
    "            tran_pc, tran_rc, tran_f1 = calculate_metrics(y_tran_pred_labl, y_tran)\n",
    "\n",
    "            # 计算验证集指标\n",
    "            y_vald_pred_prob = model(x_vald_a, x_vald_b, x_vald_c)\n",
    "            y_vald_pred_labl = (y_vald_pred_prob > 0.5).int()\n",
    "            vald_pc, vald_rc, vald_f1 = calculate_metrics(y_vald_pred_labl, y_vald)\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {avg_loss:.4f}\")\n",
    "        print(f\"Train - Precision: {tran_pc:.4f}, Recall: {tran_rc:.4f}, F1 Score: {tran_f1:.4f}\")\n",
    "        print(f\"Val   - Precision: {vald_pc:.4f}, Recall: {vald_rc:.4f}, F1 Score: {vald_f1:.4f}\")\n",
    "        print()\n",
    "\n",
    "        # 检查早停条件\n",
    "        early_stopping(avg_loss)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early Stop!\")\n",
    "            break\n",
    "\n",
    "# 测试集预测（可选）\n",
    "with torch.no_grad():\n",
    "    y_test_pred_prob = model(x_test_a, x_test_b, x_test_c)\n",
    "    y_test_pred_labl = (y_test_pred_prob > 0.5).int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_output_csv(x_test_a, y_test_pred_labl):\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    for i, row in enumerate(y_test_pred_labl):\n",
    "        if ((x_test_a[i, :100] < 1).all() or (x_test_a[i, 100:200] == 0).all() or (x_test_a[i, 200:300] == 0).all() or (x_test_a[i, 300:400] == 0).all() or (x_test_a[i, 400:500] == 0).all()):\n",
    "            result.append(\"-1\")\n",
    "        elif row.sum() == 0 or row[100] == 1:\n",
    "            result.append(\"-1\")\n",
    "        else:\n",
    "            indices = [str(idx) for idx, val in enumerate(row) if val == 1]\n",
    "            result.append(\" \".join(indices))\n",
    "    \n",
    "    result_df = pd.DataFrame({\"ID\": range(len(result)), \"Predict\": result})\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "generate_output_csv(x_test_a, y_test_pred_labl).to_csv(\"result_method2.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
