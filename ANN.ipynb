{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Feedforward Artificial Neural Network Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Import Necessary Packages & Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y = np.load(\"Data/y_train.npy\")\n",
    "x = np.load(\"Data/x_train.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x_train, x_valid, y_train, y_valid = train_test_split(x, y, test_size=0.25, random_state=random.randint(0,100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Parameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Parameter Tuning for 3-Hidden-Layer ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "case_list_3l = []\n",
    "f1_list_3l = []\n",
    "\n",
    "n_node_layer1_list = [1000, 2000, 3000]\n",
    "n_node_layer2_list = [200, 500, 1000]\n",
    "n_node_layer3_list = [50, 100, 200]\n",
    "\n",
    "for n_node_layer1 in n_node_layer1_list:\n",
    "    for n_node_layer2 in n_node_layer2_list:\n",
    "        for n_node_layer3 in n_node_layer3_list:\n",
    "            ann = Sequential()\n",
    "            ann.add(Dense(n_node_layer1, input_dim=x_train.shape[1], activation=\"tanh\"))\n",
    "            ann.add(Dropout(0.25))\n",
    "            ann.add(Dense(n_node_layer2, activation=\"tanh\"))\n",
    "            ann.add(Dropout(0.25))\n",
    "            ann.add(Dense(n_node_layer3, activation=\"tanh\"))\n",
    "            ann.add(Dropout(0.25))\n",
    "            ann.add(Dense(y_train.shape[1], activation=\"sigmoid\"))\n",
    "            ann.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")\n",
    "            ann.fit(x_train, y_train, epochs=100, batch_size=100, verbose=0)\n",
    "\n",
    "            y_valid_pre = np.where(ann.predict(x_valid) >= 0.5, 1, 0)\n",
    "            f1_list_3l.append(f1_score(y_true=y_valid, y_pred=y_valid_pre, average=\"samples\"))\n",
    "            case_list_3l.append(\"Case:\" + str(n_node_layer1) + \" \" + str(n_node_layer2) + \" \" + str(n_node_layer3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Optimal Structure for 3-layer Feedforward ANN\")\n",
    "print(case_list_3l[np.argmax(f1_list_3l)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Parameter Tuning for 4-Hidden-Layer ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "case_list_4l = []\n",
    "f1_list_4l = []\n",
    "\n",
    "n_node_layer1_list = [1000, 2000, 3000]\n",
    "n_node_layer2_list = [200, 500, 1000]\n",
    "n_node_layer3_list = [50, 100, 200]\n",
    "\n",
    "for n_node_layer1 in n_node_layer1_list:\n",
    "    for n_node_layer2 in n_node_layer2_list:\n",
    "        for n_node_layer3 in n_node_layer3_list:\n",
    "            ann = Sequential()\n",
    "            ann.add(Dense(n_node_layer1, input_dim=x_train.shape[1], activation=\"tanh\"))\n",
    "            ann.add(Dropout(0.25))\n",
    "            ann.add(Dense(n_node_layer2, activation=\"tanh\"))\n",
    "            ann.add(Dropout(0.25))\n",
    "            ann.add(Dense(n_node_layer2, activation=\"tanh\"))\n",
    "            ann.add(Dropout(0.25))\n",
    "            ann.add(Dense(n_node_layer3, activation=\"tanh\"))\n",
    "            ann.add(Dropout(0.25))\n",
    "            ann.add(Dense(y_train.shape[1], activation=\"sigmoid\"))\n",
    "            ann.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")\n",
    "            ann.fit(x_train, y_train, epochs=100, batch_size=100, verbose=0)\n",
    "\n",
    "            y_valid_pre = np.where(ann.predict(x_valid) >= 0.5, 1, 0)\n",
    "            f1_list_4l.append(f1_score(y_true=y_valid, y_pred=y_valid_pre, average=\"samples\"))\n",
    "            case_list_4l.append(\"Case:\" + str(n_node_layer1) + \" \" + str(n_node_layer2) + \" \" + str(n_node_layer3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Optimal Structure for 4-layer Feedforward ANN\")\n",
    "print(case_list_4l[np.argmax(f1_list_4l)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Parameter Tuning for 5-Hidden-Layer ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "case_list_5l = []\n",
    "f1_list_5l = []\n",
    "\n",
    "n_node_layer1_list = [1000, 2000, 3000]\n",
    "n_node_layer2_list = [200, 500, 1000]\n",
    "n_node_layer3_list = [50, 100, 200]\n",
    "activation_list = [\"tanh\"]\n",
    "\n",
    "for n_node_layer1 in n_node_layer1_list:\n",
    "    for n_node_layer2 in n_node_layer2_list:\n",
    "        for n_node_layer3 in n_node_layer3_list:\n",
    "            ann = Sequential()\n",
    "            ann.add(Dense(n_node_layer1, input_dim=x_train.shape[1], activation=\"tanh\"))\n",
    "            ann.add(Dropout(0.25))\n",
    "            ann.add(Dense(n_node_layer2, activation=\"tanh\"))\n",
    "            ann.add(Dropout(0.25))\n",
    "            ann.add(Dense(n_node_layer2, activation=\"tanh\"))\n",
    "            ann.add(Dropout(0.25))\n",
    "            ann.add(Dense(n_node_layer3, activation=\"tanh\"))\n",
    "            ann.add(Dropout(0.25))\n",
    "            ann.add(Dense(n_node_layer3, activation=\"tanh\"))\n",
    "            ann.add(Dropout(0.25))\n",
    "            ann.add(Dense(y_train.shape[1], activation=\"sigmoid\"))\n",
    "            ann.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")\n",
    "            ann.fit(x_train, y_train, epochs=100, batch_size=100, verbose=0)\n",
    "\n",
    "            y_valid_pre = np.where(ann.predict(x_valid) >= 0.5, 1, 0)\n",
    "            f1_list_5l.append(f1_score(y_true=y_valid, y_pred=y_valid_pre, average=\"samples\"))\n",
    "            case_list_5l.append(\"Case:\" + str(n_node_layer1) + \" \" + str(n_node_layer2) + \" \" + str(n_node_layer3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Optimal Structure for 5-layer Feedforward ANN\")\n",
    "print(case_list_5l[np.argmax(f1_list_5l)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Train the Optimal FANN Model & Predict on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ann = Sequential()\n",
    "ann.add(Dense(2000, input_dim=x.shape[1], activation=\"tanh\"))\n",
    "ann.add(Dropout(0.25))\n",
    "ann.add(Dense(500, activation=\"tanh\"))\n",
    "ann.add(Dropout(0.25))\n",
    "ann.add(Dense(500, activation=\"tanh\"))\n",
    "ann.add(Dropout(0.25))\n",
    "ann.add(Dense(100, activation=\"tanh\"))\n",
    "ann.add(Dropout(0.25))\n",
    "ann.add(Dense(y.shape[1], activation=\"sigmoid\"))\n",
    "ann.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")\n",
    "ann.fit(x, y, epochs=100, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x_test = np.load(\"x_test.npy\")\n",
    "y_pred = np.where(ann.predict(x_test) >= 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Generate Output File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "prediction = []\n",
    "for j in range(800):\n",
    "    p = y_pred[j]\n",
    "    r = []\n",
    "    for i in range(101):\n",
    "        if p[i].item() == 1:\n",
    "            r.append(i)\n",
    "    prediction.append(r)\n",
    "\n",
    "for k in range(800):\n",
    "    if len(prediction[k]) > 1 and 100 in prediction[k]:\n",
    "        prediction[k].remove(100)\n",
    "    elif len(prediction[k]) == 1 and 100 in prediction[k]:\n",
    "        prediction[k].remove(100)\n",
    "        prediction[k].append(-1)\n",
    "\n",
    "prediction = np.array(prediction).reshape(800,1)\n",
    "df = pd.DataFrame(prediction, columns = [\"Predict\"])\n",
    "df.to_csv(\"group_50_ann.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
